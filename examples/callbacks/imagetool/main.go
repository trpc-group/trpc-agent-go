//
// Tencent is pleased to support the open source community by making trpc-agent-go available.
//
// Copyright (C) 2025 Tencent.  All rights reserved.
//
// trpc-agent-go is licensed under the Apache License Version 2.0.
//

// Package main demonstrates how to use ToolResultMessages to turn a tool
// result that contains raw image bytes into a combination of:
//   - a RoleTool JSON message, and
//   - a RoleUser message with ContentParts including an image.
//
// This example uses a simple in-memory PNG image generated by a normal
// function tool (not MCP) to keep the focus on the callback logic.
package main

import (
	"bytes"
	"context"
	"flag"
	"fmt"
	"image"
	"image/color"
	"image/png"
	"log"
	"os"

	"trpc.group/trpc-go/trpc-agent-go/agent/llmagent"
	"trpc.group/trpc-go/trpc-agent-go/model"
	"trpc.group/trpc-go/trpc-agent-go/model/openai"
	"trpc.group/trpc-go/trpc-agent-go/runner"
	"trpc.group/trpc-go/trpc-agent-go/session/inmemory"
	"trpc.group/trpc-go/trpc-agent-go/tool"
	"trpc.group/trpc-go/trpc-agent-go/tool/function"
)

var (
	modelName = flag.String("model", os.Getenv("MODEL_NAME"), "Model name (e.g. gpt-4.1, qwen3-omni-30b-a3b-thinking)")
)

// README (imagetool example)
//
// This example shows how to:
//   - implement a normal function tool that returns raw PNG bytes, and
//   - use ToolResultMessages to expose that result to OpenAI‑style models as:
//       * a RoleTool JSON message (default behavior), plus
//       * a RoleUser message with ContentParts that includes an image.
//
// Important notes when copying this pattern into your own code:
//   1) ToolResultMessages is optional.
//      - If the callback returns nil or an empty slice, the framework will send
//        the default RoleTool JSON message only (backwards compatible behavior).
//   2) When you register ToolResultMessages, you are responsible for protocol correctness.
//      - The framework only type‑checks the return value (model.Message or []model.Message)
//        and wraps it into choices; it does not fix Role / ToolID for you.
//      - If you drop the RoleTool message or set a wrong ToolID, some providers
//        (including OpenAI‑compatible proxies) may return 4xx errors.
//   3) Keep at least one RoleTool message per tool_call when you rely on
//      OpenAI‑style function calling.
//      - In this example we keep the original DefaultToolMessage as the tool result
//        and only add an extra RoleUser(message_with_image) on top of it.
//   4) Image bytes should be real binary data, not a second layer of base64.
//      - The tool returns PNG bytes in imageToolResult.Data.
//      - The OpenAI adapter (openai-go) will take model.Image{Data: ...} and
//        encode or wrap it as image_url for the underlying HTTP API; you should
//        not base64‑encode the data again in the callback.
//   5) The callback is called once per tool call.
//      - Do not mix results from different tool_call_ids into a single slice;
//        always treat ToolResultMessagesInput.ToolCallID as the scope boundary.

// imageToolArgs represents arguments for the demo image tool.
type imageToolArgs struct {
	Label string `json:"label" jsonschema:"description=Optional short description for the generated image"`
}

// imageToolResult represents the result of the demo image tool.
type imageToolResult struct {
	Title  string `json:"title"`
	Data   []byte `json:"data"`
	Format string `json:"format"`
}

func main() {
	flag.Parse()

	if *modelName == "" {
		*modelName = "gpt-4.1-mini"
	}

	fmt.Printf("▶ imagetool callback example\n")
	fmt.Printf("Model: %s\n", *modelName)

	ctx := context.Background()

	// Configure tool callbacks with ToolResultMessages.
	toolCallbacks := tool.NewCallbacks()
	toolCallbacks.RegisterToolResultMessages(toolResultMessagesCallback)

	// Create the model and tool.
	llm := openai.New(*modelName)
	imageTool := function.NewFunctionTool(
		generateDemoImage,
		function.WithName("demo_image_tool"),
		function.WithDescription("Generate a small demo PNG image and return it to the model"),
	)

	// Build an LLM agent.
	genConfig := model.GenerationConfig{
		Stream: false,
	}
	agent := llmagent.New(
		"imagetool-agent",
		llmagent.WithModel(llm),
		llmagent.WithDescription("Agent that can generate a demo image via a tool"),
		llmagent.WithInstruction("First call demo_image_tool, then describe the image you received."),
		llmagent.WithGenerationConfig(genConfig),
		llmagent.WithTools([]tool.Tool{imageTool}),
		llmagent.WithToolCallbacks(toolCallbacks),
	)

	r := runner.NewRunner(
		"imagetool-runner",
		agent,
		runner.WithSessionService(inmemory.NewSessionService()),
	)
	defer r.Close()

	// Ask the model to use the tool and then describe the image.
	msg := model.NewUserMessage("First call demo_image_tool to generate an image, then describe what is in the image.")
	events, err := r.Run(ctx, "demo-user", "session-imagetool", msg)
	if err != nil {
		log.Fatalf("run failed: %v", err)
	}

	for ev := range events {
		if ev.Error != nil {
			fmt.Printf("⚠ error event: %s\n", ev.Error.Message)
			continue
		}
		if ev.Response == nil || len(ev.Response.Choices) == 0 {
			continue
		}
		choice := ev.Response.Choices[0]
		if choice.Message.Role == model.RoleAssistant && choice.Message.Content != "" && ev.IsFinalResponse() {
			fmt.Printf("\nAssistant:\n%s\n", choice.Message.Content)
		}
	}
}

// generateDemoImage is a normal function tool that returns a small PNG
// in memory. It does not know anything about OpenAI or image_url; the
// conversion is handled entirely by ToolResultMessages.
func generateDemoImage(_ context.Context, args *imageToolArgs) (*imageToolResult, error) {
	const width, height = 64, 64

	img := image.NewRGBA(image.Rect(0, 0, width, height))
	bg := color.RGBA{R: 34, G: 139, B: 230, A: 255}
	for y := 0; y < height; y++ {
		for x := 0; x < width; x++ {
			img.Set(x, y, bg)
		}
	}

	var buf bytes.Buffer
	if err := png.Encode(&buf, img); err != nil {
		return nil, err
	}

	title := "A demo PNG image generated by demo_image_tool."
	if args != nil && args.Label != "" {
		title = args.Label
	}

	return &imageToolResult{
		Title:  title,
		Data:   buf.Bytes(),
		Format: "png",
	}, nil
}

// toolResultMessagesCallback demonstrates how to map a tool result into
// tool + user(image) messages. It keeps the default RoleTool JSON text
// message and appends a RoleUser message carrying the image via ContentParts.
func toolResultMessagesCallback(ctx context.Context, in *tool.ToolResultMessagesInput) (any, error) {
	_ = ctx

	if in.ToolName != "demo_image_tool" {
		// Only customize the demo image tool; other tools use default behavior.
		return nil, nil
	}

	result, ok := in.Result.(*imageToolResult)
	if !ok || result == nil || len(result.Data) == 0 {
		return nil, nil
	}

	defaultMsg, ok := in.DefaultToolMessage.(model.Message)
	if !ok {
		return nil, nil
	}

	text := result.Title
	if text == "" {
		text = "Demo image returned from demo_image_tool."
	}

	imagePart := model.Image{
		Data:   result.Data,
		Format: result.Format,
	}

	parts := []model.ContentPart{
		{
			Type: model.ContentTypeText,
			Text: &text,
		},
		{
			Type:  model.ContentTypeImage,
			Image: &imagePart,
		},
	}

	userMsg := model.Message{
		Role:         model.RoleUser,
		ContentParts: parts,
		ToolID:       in.ToolCallID,
	}

	// Send both the original RoleTool JSON message and the synthetic
	// RoleUser(image) message back to the model.
	return []model.Message{defaultMsg, userMsg}, nil
}
