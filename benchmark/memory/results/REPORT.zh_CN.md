# 长期对话记忆能力评估：基于 LoCoMo 基准的实证研究

## 1. 引言

长期对话记忆是 AI Agent 在多轮会话中与用户交互的核心能力。随着对话不断累积，Agent 需要有效地存储、检索和推理过去的交互内容，以保持连贯且个性化的回复。

本报告使用 **LoCoMo**（Long-Context Conversational Memory）基准评估 trpc-agent-go 的记忆能力，在两种存储后端上对比三种不同的记忆范式，并进一步研究在记忆方案中注入原始对话历史（300 轮和 700 轮）作为额外上下文的效果。

**核心发现：**

- **长上下文基线** 取得最高 F1（0.472），在上下文窗口允许的情况下，完整对话仍是最优方案
- **自动记忆提取**（F1=0.357 pgvector）是最强的记忆方案，达到长上下文基线的 75.6%
- **Agentic 记忆**（F1=0.294 pgvector）显示 LLM 驱动的记忆提取面临信息密度挑战
- **pgvector 始终优于 MySQL** 1-2% F1，验证了向量相似度搜索的价值
- **注入原始历史降低 F1/BLEU 但提升 LLM Score**，揭示了 Token 级精度与语义质量之间的权衡

---

## 2. 方法

### 2.1 基准数据集

使用 **LoCoMo** 数据集（Maharana et al., 2024），包含多个会话对之间的多轮对话：

- 每个样本包含 15-25 个跨数月的对话 session
- 涵盖 5 个类别的 ground-truth QA 对
- 提供 session 级别的 observation 和 summary

**评估规模**：10 个样本，共 1,986 个 QA 对

### 2.2 评估场景

| 场景 | 描述 | 记忆写入 | 记忆读取 |
| --- | --- | --- | --- |
| **Long-Context** | 完整对话作为 LLM 上下文 | 无（全部放入上下文） | 无 |
| **Agentic** | LLM Agent 通过工具调用决定存储内容 | LLM 工具调用 (memory_add) | 记忆检索 |
| **Auto** | 后台提取器自动生成记忆 | 异步提取 | 记忆检索 |

### 2.3 存储后端

| 后端 | 检索方式 | Embedding 模型 |
| --- | --- | --- |
| **pgvector** | 向量相似度（余弦） | text-embedding-3-small |
| **MySQL** | 全文搜索（类 BM25） | 无 |

### 2.4 历史注入实验

在基础场景之外，我们评估将原始对话历史轮次作为上下文消息注入记忆检索结果中：

| 变体 | 描述 |
| --- | --- |
| **无历史** | 仅记忆检索（记忆场景的基线） |
| **+300 轮历史** | 注入最近 300 轮对话作为上下文 |
| **+700 轮历史** | 注入最近 700 轮对话作为上下文 |

历史消息通过 `WithInjectedContextMessages` 注入到 system prompt 之后、session history 之前。

### 2.5 评估指标

与 LoCoMo 论文及业界标准（Mem0, MemMachine）对齐：

| 指标 | 描述 |
| --- | --- |
| **F1 Score** | Token 级别 F1（主要指标） |
| **BLEU Score** | N-gram 重叠精度 |
| **LLM Score** | LLM-as-Judge 语义评估 (0-1) |

### 2.6 QA 分类

| 类别 | 数量 | 描述 |
| --- | --- | --- |
| single-hop | 282 | 单跳问题，来自单个对话片段 |
| multi-hop | 321 | 多跳问题，需要组合多个片段的信息 |
| temporal | 96 | 时间推理问题 |
| open-domain | 841 | 开放域问题，需要世界知识 |
| adversarial | 446 | 对抗性问题，测试鲁棒性（不可回答） |

### 2.7 实验配置

| 参数 | 值 |
| --- | --- |
| 模型 | gpt-4o-mini |
| 评估模型 | gpt-4o-mini |
| 样本数 | 10（完整 LoCoMo-10） |
| 总问题数 | 1,986 |
| LLM 评判 | 启用 |

---

## 3. 结果

### 3.1 总体结果（无历史注入）

| 场景 | 后端 | F1 | BLEU | LLM Score | 平均延迟 |
| --- | --- | ---: | ---: | ---: | ---: |
| Long-Context | - | **0.472** | **0.429** | **0.523** | 3,485ms |
| Auto | pgvector | 0.357 | 0.333 | 0.366 | 5,622ms |
| Auto | MySQL | 0.347 | 0.320 | 0.362 | 5,678ms |
| Agentic | pgvector | 0.294 | 0.279 | 0.287 | 4,998ms |
| Agentic | MySQL | 0.286 | 0.271 | 0.285 | 4,392ms |

### 3.2 历史注入结果

**表 1：历史注入对总体指标的影响**

| 场景 | 后端 | 历史 | F1 | BLEU | LLM Score | 平均延迟 |
| --- | --- | --- | ---: | ---: | ---: | ---: |
| Agentic | pgvector | 无 | **0.294** | **0.279** | 0.287 | 4,998ms |
| Agentic | pgvector | +300 | 0.267 | 0.237 | 0.357 | 6,990ms |
| Agentic | pgvector | +700 | 0.275 | 0.229 | **0.464** | 5,120ms |
| Agentic | MySQL | 无 | **0.286** | **0.271** | 0.285 | 4,392ms |
| Agentic | MySQL | +300 | 0.275 | 0.245 | 0.365 | 5,817ms |
| Agentic | MySQL | +700 | 0.277 | 0.231 | **0.460** | 4,956ms |
| Auto | pgvector | 无 | **0.357** | **0.333** | 0.366 | 5,622ms |
| Auto | pgvector | +300 | 0.296 | 0.260 | 0.414 | 6,056ms |
| Auto | pgvector | +700 | 0.288 | 0.242 | **0.464** | 5,852ms |
| Auto | MySQL | 无 | **0.347** | **0.320** | 0.362 | 5,678ms |
| Auto | MySQL | +300 | 0.280 | 0.246 | 0.399 | 5,547ms |
| Auto | MySQL | +700 | 0.290 | 0.244 | **0.467** | 5,321ms |

### 3.3 各类别结果（无历史）

**表 2：各类别 F1 分数**

| 类别 | Long-Context | Agentic pgvec | Agentic MySQL | Auto pgvec | Auto MySQL |
| --- | ---: | ---: | ---: | ---: | ---: |
| single-hop | 0.330 | 0.146 | 0.168 | 0.272 | 0.306 |
| multi-hop | 0.319 | 0.178 | 0.135 | 0.088 | 0.101 |
| temporal | 0.088 | 0.091 | 0.043 | 0.060 | 0.056 |
| open-domain | 0.518 | 0.126 | 0.146 | 0.302 | 0.325 |
| adversarial | 0.668 | 0.830 | 0.787 | 0.771 | 0.653 |

**表 3：各类别 LLM Score**

| 类别 | Long-Context | Agentic pgvec | Agentic MySQL | Auto pgvec | Auto MySQL |
| --- | ---: | ---: | ---: | ---: | ---: |
| single-hop | 0.333 | 0.122 | 0.130 | 0.220 | 0.277 |
| multi-hop | 0.252 | 0.107 | 0.093 | 0.049 | 0.064 |
| temporal | 0.155 | 0.137 | 0.057 | 0.068 | 0.083 |
| open-domain | 0.654 | 0.141 | 0.171 | 0.355 | 0.380 |
| adversarial | 0.670 | 0.830 | 0.787 | 0.771 | 0.653 |

### 3.4 历史注入：类别分解

**表 4：各类别 F1 — Agentic pgvector**

| 类别 | 无历史 | +300 | +700 |
| --- | ---: | ---: | ---: |
| single-hop | **0.146** | 0.156 | 0.185 |
| multi-hop | **0.178** | 0.123 | 0.112 |
| temporal | 0.091 | 0.062 | **0.089** |
| open-domain | 0.126 | 0.239 | **0.331** |
| adversarial | **0.830** | 0.539 | 0.383 |

**表 5：各类别 F1 — Auto pgvector**

| 类别 | 无历史 | +300 | +700 |
| --- | ---: | ---: | ---: |
| single-hop | **0.272** | 0.196 | 0.183 |
| multi-hop | 0.088 | **0.120** | 0.106 |
| temporal | 0.060 | **0.074** | 0.079 |
| open-domain | 0.302 | **0.306** | **0.347** |
| adversarial | **0.771** | 0.514 | 0.418 |

**表 6：各类别 LLM Score — Auto pgvector**

| 类别 | 无历史 | +300 | +700 |
| --- | ---: | ---: | ---: |
| single-hop | 0.220 | 0.294 | **0.291** |
| multi-hop | 0.049 | 0.131 | **0.182** |
| temporal | 0.068 | 0.162 | **0.185** |
| open-domain | 0.355 | 0.539 | **0.685** |
| adversarial | **0.771** | 0.513 | 0.419 |

### 3.5 各样本 F1 分数

**表 7：各样本 F1（Long-Context / Auto pgvector / Agentic pgvector）**

| 样本 | QA 数 | Long-Context | Auto pgvec | Agentic pgvec |
| --- | ---: | ---: | ---: | ---: |
| locomo10_1 | 199 | 0.429 | 0.311 | 0.279 |
| locomo10_2 | 105 | 0.510 | 0.322 | 0.345 |
| locomo10_3 | 193 | 0.530 | 0.441 | 0.295 |
| locomo10_4 | 260 | 0.456 | 0.367 | 0.335 |
| locomo10_5 | 242 | 0.447 | 0.364 | 0.297 |
| locomo10_6 | 158 | 0.539 | 0.204 | 0.287 |
| locomo10_7 | 190 | 0.465 | 0.404 | 0.278 |
| locomo10_8 | 239 | 0.461 | 0.339 | 0.268 |
| locomo10_9 | 196 | 0.448 | 0.380 | 0.268 |
| locomo10_10 | 204 | 0.480 | 0.393 | 0.297 |
| **平均** | **199** | **0.472** | **0.357** | **0.294** |

---

## 4. 分析

### 4.1 场景对比

```
F1 Score Comparison (10 samples, 1986 QA pairs)

long_context        |==========================================| 0.472
auto_pgvec          |================================          | 0.357
auto_mysql          |===============================           | 0.347
auto_pgvec +300     |===========================               | 0.296
auto_mysql +700     |==========================                | 0.290
auto_pgvec +700     |==========================                | 0.288
agentic_pgvec       |==========================                | 0.294
auto_mysql +300     |=========================                 | 0.280
agentic_mysql +700  |=========================                 | 0.277
agentic_mysql       |=========================                 | 0.286
agentic_mysql +300  |========================                  | 0.275
agentic_pgvec +700  |========================                  | 0.275
agentic_pgvec +300  |=======================                   | 0.267
                    +------------------------------------------+
                    0.0      0.1      0.2      0.3      0.4   0.5

LLM Score Comparison (10 samples, 1986 QA pairs)

long_context        |==========================================| 0.523
auto_mysql +700     |=====================================     | 0.467
auto_pgvec +700     |=====================================     | 0.464
agentic_pgvec +700  |=====================================     | 0.464
agentic_mysql +700  |====================================      | 0.460
auto_pgvec +300     |=================================         | 0.414
auto_mysql +300     |================================          | 0.399
auto_pgvec          |=============================             | 0.366
agentic_mysql +300  |=============================             | 0.365
auto_mysql          |============================              | 0.362
agentic_pgvec +300  |============================              | 0.357
agentic_pgvec       |=======================                   | 0.287
agentic_mysql       |=======================                   | 0.285
                    +------------------------------------------+
                    0.0      0.1      0.2      0.3      0.4   0.5
```

#### 4.1.1 长上下文是金标准

长上下文取得最高 F1（0.472），在除对抗性外的所有类别中均最优。这确认了在上下文窗口允许时，提供完整对话文本仍然是最佳方案。但这种方法无法扩展到任意长度的对话历史。

#### 4.1.2 自动提取优于 Agentic

自动记忆提取（F1=0.357）显著优于 Agentic（0.294）。自动提取更系统化——处理所有对话内容，而非依赖 LLM Agent 的选择性工具调用，生成更高密度、语义更丰富的记忆。

#### 4.1.3 对抗鲁棒性与召回能力呈反相关

记忆方案达到较高对抗 F1（0.653-0.830），而长上下文仅 0.668。这是因为基于记忆的方法在未检索到相关记忆时自然返回"信息不可用"，这恰好是对抗性问题的正确答案。而长上下文有完整文本可用时，更容易产生看似合理但实际错误的回答。

### 4.2 历史注入分析

#### 4.2.1 注入历史导致 F1/BLEU 下降

在所有 4 个场景-后端组合中，注入对话历史一致地降低了 F1 和 BLEU 分数：

| 场景 | 后端 | F1（无） | F1（+300） | F1（+700） | 变化 |
| --- | --- | ---: | ---: | ---: | ---: |
| Auto | pgvector | 0.357 | 0.296 | 0.288 | -0.069 |
| Auto | MySQL | 0.347 | 0.280 | 0.290 | -0.057 |
| Agentic | pgvector | 0.294 | 0.267 | 0.275 | -0.019 |
| Agentic | MySQL | 0.286 | 0.275 | 0.277 | -0.009 |

主要原因是**对抗性分数崩溃**。无历史时，对抗性 F1 在 0.653-0.830 之间；注入 +700 轮历史后降至 0.383-0.418。模型在有大量原始对话上下文时，会尝试回答本应拒绝的问题，在对抗性类别（占全部问题的 22%）上损失约 0.35-0.45 F1。

#### 4.2.2 LLM Score 显著提升

虽然 F1/BLEU 下降，但 LLM-as-Judge 分数显著提升：

| 场景 | 后端 | LLM（无） | LLM（+300） | LLM（+700） | 变化 |
| --- | --- | ---: | ---: | ---: | ---: |
| Auto | pgvector | 0.366 | 0.414 | 0.464 | +0.098 |
| Auto | MySQL | 0.362 | 0.399 | 0.467 | +0.105 |
| Agentic | pgvector | 0.287 | 0.357 | 0.464 | +0.177 |
| Agentic | MySQL | 0.285 | 0.365 | 0.460 | +0.175 |

这揭示了一个根本性矛盾：注入的历史使回答在语义上更丰富、更贴合上下文（LLM Score 更高），但也更冗长、与参考答案偏差更大（F1/BLEU 更低）。

#### 4.2.3 开放域问题受益最大

Auto pgvector 的开放域 LLM Score 提升显著：
- 无历史：0.355
- +300：0.539（+51.8%）
- +700：0.685（+92.9%）

这很合理：关于偏好、观点和经历的开放域问题，需要访问离散记忆可能无法捕捉的原始对话细节。

#### 4.2.4 从 300 到 700 轮的边际递减

从 300 到 700 轮的提升相比 0 到 300 是边际性的：
- Auto pgvector LLM Score：0.366 → 0.414（+0.048）→ 0.464（+0.050）
- Auto pgvector F1：0.357 → 0.296（-0.061）→ 0.288（-0.008）

F1 下降在 300 轮后趋于平稳，而 LLM Score 继续线性提升。这表明约 300 轮已捕获了大部分有用的对话上下文，超过后边际收益递减。

### 4.3 类别分析

#### 4.3.1 时间推理普遍薄弱

时间类问题在所有场景中 F1 最低（0.043-0.091），包括长上下文（0.088）。这表明时间推理对 gpt-4o-mini 来说本质上很困难，与记忆架构无关。

根本原因：
- 对话使用相对时间引用（"去年"、"下个月"），需要根据 session 日期进行解析
- 即使记忆中有明确的 `[DATE:]` 前缀，模型仍难以计算时间关系

#### 4.3.2 多跳推理受益于 Agentic 记忆

Agentic（pgvector）在记忆方案中取得最高多跳 F1（0.178），超越 Auto（0.088）。这表明 Agentic 方法虽然总体提取的记忆较少，但创建了更具关联性的知识，有助于多跳推理。`datePrefixMemoryService` 注入的 `[DATE:]` 前缀对此有贡献。

#### 4.3.3 开放域问题依赖丰富上下文

长上下文在开放域问题中占据主导（F1=0.518），而记忆方案表现较弱（0.126-0.302）。开放域问题通常需要对对话上下文、偏好和态度的细致理解，这些很难用离散的记忆条目捕获。历史注入部分弥补了这一差距（Auto pgvector 开放域 LLM Score：0.355 → 0.685）。

### 4.4 后端对比：pgvector vs MySQL

| 场景 | pgvector F1 | MySQL F1 | 差值 |
| --- | ---: | ---: | ---: |
| Agentic | 0.294 | 0.286 | +0.008 |
| Auto | 0.357 | 0.347 | +0.010 |
| Agentic +700 | 0.275 | 0.277 | -0.002 |
| Auto +700 | 0.288 | 0.290 | -0.002 |

无历史注入时 pgvector 优于 MySQL。但**注入历史后，后端差异消失**——注入的对话上下文主导了检索质量，使后端选择变得不那么重要。

### 4.5 方差分析

各样本 F1 分数显示明显方差：
- **长上下文**：0.429 - 0.539（范围 0.110），相对稳定
- **Auto pgvector**：0.204 - 0.441（范围 0.237），方差较大

记忆方案的高方差表明，某些对话结构本质上更难进行记忆提取和检索。话题交错更复杂的样本（如 locomo10_6, locomo10_8）得分往往更低。

---

## 5. 与外部基线对比

| 系统 | 模型 | F1 | 备注 |
| --- | --- | ---: | --- |
| GPT-4 (4K context) | GPT-4 | 0.321 | LoCoMo 论文基线 |
| GPT-3.5-16K | GPT-3.5 | 0.378 | LoCoMo 论文基线 |
| **trpc-agent-go (Long-Context)** | gpt-4o-mini | **0.472** | 本工作 |
| **trpc-agent-go (Auto pgvector)** | gpt-4o-mini | **0.357** | 本工作 |

> 注：由于模型版本和配置不同，直接对比仅供参考

长上下文结果（0.472）显著超越 LoCoMo 的 GPT-4 4K 基线（0.321），得益于 gpt-4o-mini 更大的上下文窗口。Auto pgvector 结果（0.357）与 GPT-3.5-16K 全上下文性能（0.378）接近。

---

## 6. 讨论

### 6.1 当前实现的优势

1. **日期感知记忆服务**：`datePrefixMemoryService` 自动为 Agentic 记忆注入 `[DATE: ...]` 前缀，无需依赖 LLM 遵从指令即可改善时间推理
2. **强对抗鲁棒性**：记忆方案达到 0.65-0.83 的对抗 F1，能正确识别不可回答问题
3. **自动提取方案**：后台提取器在记忆质量和系统复杂度之间提供了良好平衡

### 6.2 历史注入的权衡

历史注入实验揭示了记忆系统设计的关键洞察：

- **纯记忆**（无历史）：最佳 F1/BLEU，最佳对抗鲁棒性，但语义质量较低
- **记忆 + 历史**：最佳 LLM Score 和开放域表现，但精确指标和对抗鲁棒性下降

这表明**混合方案**适合生产环境：将记忆检索作为主要上下文来源，在检测到开放域或需要细致理解的问题时，选择性地注入相关历史片段（而非全部 300-700 轮）。

### 6.3 局限性与未来工作

1. **时间推理仍然薄弱**（所有场景 F1 < 0.1），后续应探索专用时间索引和推理模块
2. **多跳推理差距**：记忆方案难以跨 session 组合事实，图结构记忆可能有帮助
3. **开放域性能**：记忆压缩不可避免地丢失细节，分层记忆（摘要 + 细节）可能弥补此差距
4. **模型能力上限**：gpt-4o-mini 的提取和推理能力限制了所有场景，更强的模型（如 GPT-4o、Claude）可能显著改善结果
5. **选择性历史注入**：不注入全部轮次，而是使用相关性过滤只注入相关的对话片段

### 6.4 生产使用建议

| 使用场景 | 推荐方案 |
| --- | --- |
| 短对话历史 (< 50K tokens) | 长上下文（无需记忆） |
| 长期运行的 Agent（数月历史） | 自动提取 + pgvector |
| 语义质量优先 | 记忆 + 选择性历史注入 |
| 低延迟要求 | Agentic + MySQL |

---

## 7. 结论

本评估证明 trpc-agent-go 的记忆系统在多种范式下均能提供有效的长期对话记忆。自动提取 + pgvector 方案取得了最佳的召回与鲁棒性平衡，达到长上下文基线 F1 的 75.6%，同时保持强对抗鲁棒性（0.771）。

历史注入实验揭示了一个重要权衡：注入原始对话历史提升了语义质量（LLM Score +0.10~0.18），但降低了 Token 级精度（F1 -0.02~0.07）和对抗鲁棒性。这确认了**结构化记忆提取在事实召回任务上比暴力上下文注入更有效**，而历史注入对开放域、需要细致理解的问题有附加价值。

核心结论：
1. **Auto > Agentic**：在 gpt-4o-mini 下的记忆方案有效性排序
2. **pgvector > MySQL**：语义检索质量始终更优（无历史注入时）
3. **时间推理** 是所有方案的主要瓶颈
4. **对抗鲁棒性** 是记忆系统的天然优势
5. **历史注入** 提升语义质量但降低精度——推荐混合选择性方案

---

## 附录

### A. 实验环境

| 组件 | 版本/配置 |
| --- | --- |
| 框架 | trpc-agent-go |
| 模型 | gpt-4o-mini |
| Embedding | text-embedding-3-small |
| PostgreSQL | 15+ with pgvector extension |
| MySQL | 8.0+ with full-text search |
| 数据集 | LoCoMo-10（10 样本，1,986 QA） |

### B. 完整类别数据 — 无历史（F1 / BLEU / LLM）

| 场景 | single-hop | multi-hop | temporal | open-domain | adversarial |
| --- | --- | --- | --- | --- | --- |
| Long-Context | 0.330/0.260/0.333 | 0.319/0.285/0.252 | 0.088/0.069/0.155 | 0.518/0.456/0.654 | 0.668/0.667/0.670 |
| Agentic pgvec | 0.146/0.106/0.122 | 0.178/0.160/0.107 | 0.091/0.075/0.137 | 0.126/0.114/0.141 | 0.830/0.830/0.830 |
| Agentic MySQL | 0.168/0.125/0.130 | 0.135/0.119/0.093 | 0.043/0.034/0.057 | 0.146/0.132/0.171 | 0.787/0.787/0.787 |
| Auto pgvec | 0.272/0.209/0.220 | 0.088/0.081/0.049 | 0.060/0.047/0.068 | 0.302/0.271/0.355 | 0.771/0.771/0.771 |
| Auto MySQL | 0.306/0.232/0.277 | 0.101/0.092/0.064 | 0.056/0.040/0.083 | 0.325/0.293/0.380 | 0.653/0.653/0.653 |

### C. 完整类别数据 — +700 轮历史（F1 / BLEU / LLM）

| 场景 | single-hop | multi-hop | temporal | open-domain | adversarial |
| --- | --- | --- | --- | --- | --- |
| Agentic pgvec | 0.185/0.142/0.310 | 0.112/0.085/0.212 | 0.089/0.066/0.225 | 0.331/0.249/0.677 | 0.383/0.382/0.391 |
| Agentic MySQL | 0.188/0.144/0.290 | 0.096/0.073/0.191 | 0.084/0.064/0.212 | 0.332/0.250/0.675 | 0.403/0.401/0.408 |
| Auto pgvec | 0.183/0.140/0.291 | 0.106/0.083/0.182 | 0.079/0.057/0.185 | 0.347/0.265/0.685 | 0.418/0.417/0.419 |
| Auto MySQL | 0.181/0.137/0.297 | 0.100/0.079/0.177 | 0.112/0.090/0.205 | 0.354/0.272/0.692 | 0.412/0.411/0.414 |

### D. 完整类别数据 — +300 轮历史（F1 / BLEU / LLM）

| 场景 | single-hop | multi-hop | temporal | open-domain | adversarial |
| --- | --- | --- | --- | --- | --- |
| Agentic pgvec | 0.156/0.122/0.227 | 0.123/0.096/0.103 | 0.062/0.049/0.114 | 0.239/0.191/0.429 | 0.539/0.539/0.540 |
| Agentic MySQL | 0.156/0.122/0.215 | 0.117/0.092/0.114 | 0.061/0.047/0.139 | 0.237/0.190/0.423 | 0.579/0.579/0.580 |
| Auto pgvec | 0.196/0.152/0.294 | 0.120/0.099/0.131 | 0.074/0.058/0.162 | 0.306/0.246/0.539 | 0.514/0.514/0.513 |
| Auto MySQL | 0.180/0.142/0.261 | 0.095/0.079/0.113 | 0.080/0.065/0.163 | 0.297/0.237/0.534 | 0.488/0.487/0.487 |

### E. 总评估时间

| 场景 | 后端 | 历史 | 总时间 | 平均延迟/QA |
| --- | --- | --- | --- | --- |
| Long-Context | - | - | 1h55m | 3,485ms |
| Agentic | pgvector | 无 | 2h45m | 4,998ms |
| Agentic | MySQL | 无 | 2h25m | 4,392ms |
| Auto | pgvector | 无 | 3h06m | 5,622ms |
| Auto | MySQL | 无 | 3h08m | 5,678ms |
| Agentic | pgvector | +300 | 3h51m | 6,990ms |
| Agentic | MySQL | +300 | 3h13m | 5,817ms |
| Auto | pgvector | +300 | 3h20m | 6,056ms |
| Auto | MySQL | +300 | 3h04m | 5,547ms |
| Agentic | pgvector | +700 | 2h49m | 5,120ms |
| Agentic | MySQL | +700 | 2h44m | 4,956ms |
| Auto | pgvector | +700 | 3h14m | 5,852ms |
| Auto | MySQL | +700 | 2h56m | 5,321ms |

---

## 参考文献

1. Maharana, A., Lee, D., Tulyakov, S., Bansal, M., Barbieri, F., and Fang, Y. "LoCoMo: Long-Context Conversational Memory." arXiv:2402.17753, 2024.
2. Hu, C., et al. "Memory in the Age of AI Agents." arXiv:2512.13564, 2024.
