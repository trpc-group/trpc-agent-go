# 长期对话记忆能力评估：基于 LoCoMo 基准的实证研究

## 1. 引言

长期对话记忆是 AI Agent 在多轮会话中与用户交互的核心能力。随着对话不断累积，Agent 需要有效地存储、检索和推理过去的交互内容，以保持连贯且个性化的回复。

本报告使用 **LoCoMo**（Long-Context Conversational Memory）基准评估 trpc-agent-go 的记忆能力，在两种存储后端上对比三种不同的记忆范式，分析各自在不同问题类别上的优劣。

**核心发现：**

- **长上下文基线** 取得最高 F1（0.472），在上下文窗口允许的情况下，完整对话仍是最优方案
- **自动记忆提取**（F1=0.357 pgvector）是最强的记忆方案，达到长上下文基线的 75.6%
- **Agentic 记忆**（F1=0.294 pgvector）显示 LLM 驱动的记忆提取面临信息密度挑战
- **pgvector 始终优于 MySQL** 1-2% F1，验证了向量相似度搜索的价值

---

## 2. 方法

### 2.1 基准数据集

使用 **LoCoMo** 数据集（Maharana et al., 2024），包含多个会话对之间的多轮对话：

- 每个样本包含 15-25 个跨数月的对话 session
- 涵盖 5 个类别的 ground-truth QA 对
- 提供 session 级别的 observation 和 summary

**评估规模**：10 个样本，共 1,986 个 QA 对

### 2.2 评估场景

| 场景 | 描述 | 记忆写入 | 记忆读取 |
| --- | --- | --- | --- |
| **Long-Context** | 完整对话作为 LLM 上下文 | 无（全部放入上下文） | 无 |
| **Agentic** | LLM Agent 通过工具调用决定存储内容 | LLM 工具调用 (memory_add) | 记忆检索 |
| **Auto** | 后台提取器自动生成记忆 | 异步提取 | 记忆检索 |

### 2.3 存储后端

| 后端 | 检索方式 | Embedding 模型 |
| --- | --- | --- |
| **pgvector** | 向量相似度（余弦） | text-embedding-3-small |
| **MySQL** | 全文搜索（类 BM25） | 无 |

### 2.4 评估指标

与 LoCoMo 论文及业界标准（Mem0, MemMachine）对齐：

| 指标 | 描述 |
| --- | --- |
| **F1 Score** | Token 级别 F1（主要指标） |
| **BLEU Score** | N-gram 重叠精度 |
| **LLM Score** | LLM-as-Judge 语义评估 (0-1) |

### 2.5 QA 分类

| 类别 | 数量 | 描述 |
| --- | --- | --- |
| single-hop | 282 | 单跳问题，来自单个对话片段 |
| multi-hop | 321 | 多跳问题，需要组合多个片段的信息 |
| temporal | 96 | 时间推理问题 |
| open-domain | 841 | 开放域问题，需要世界知识 |
| adversarial | 446 | 对抗性问题，测试鲁棒性（不可回答） |

### 2.6 实验配置

| 参数 | 值 |
| --- | --- |
| 模型 | gpt-4o-mini |
| 评估模型 | gpt-4o-mini |
| 样本数 | 10（完整 LoCoMo-10） |
| 总问题数 | 1,986 |
| LLM 评判 | 启用 |

---

## 3. 结果

### 3.1 总体结果

| 场景 | 后端 | F1 | BLEU | LLM Score | 平均延迟 |
| --- | --- | ---: | ---: | ---: | ---: |
| Long-Context | - | **0.472** | **0.429** | **0.523** | 3,485ms |
| Agentic | pgvector | 0.294 | 0.279 | 0.287 | 4,998ms |
| Agentic | MySQL | 0.286 | 0.271 | 0.285 | 4,392ms |
| Auto | pgvector | 0.357 | 0.333 | 0.366 | 5,622ms |
| Auto | MySQL | 0.347 | 0.320 | 0.362 | 5,678ms |

### 3.2 各类别 F1 分数

| 类别 | Long-Context | Agentic pgvec | Agentic MySQL | Auto pgvec |
| --- | ---: | ---: | ---: | ---: |
| single-hop | 0.330 | 0.146 | 0.168 | 0.272 |
| multi-hop | 0.319 | 0.178 | 0.135 | 0.088 |
| temporal | 0.088 | 0.091 | 0.043 | 0.060 |
| open-domain | 0.518 | 0.126 | 0.146 | 0.302 |
| adversarial | 0.668 | 0.830 | 0.787 | 0.771 |

### 3.3 各样本 F1 分数

| 样本 | QA 数 | Long-Context | Auto pgvec | Agentic pgvec |
| --- | ---: | ---: | ---: | ---: |
| locomo10_1 | 199 | 0.429 | 0.311 | 0.279 |
| locomo10_2 | 105 | 0.510 | 0.322 | 0.345 |
| locomo10_3 | 193 | 0.530 | 0.441 | 0.295 |
| locomo10_4 | 260 | 0.456 | 0.367 | 0.335 |
| locomo10_5 | 242 | 0.447 | 0.364 | 0.297 |
| locomo10_6 | 158 | 0.539 | 0.204 | 0.287 |
| locomo10_7 | 190 | 0.465 | 0.404 | 0.278 |
| locomo10_8 | 239 | 0.461 | 0.339 | 0.268 |
| locomo10_9 | 196 | 0.448 | 0.380 | 0.268 |
| locomo10_10 | 204 | 0.480 | 0.393 | 0.297 |
| **平均** | **199** | **0.472** | **0.357** | **0.294** |

---

## 4. 分析

### 4.1 场景对比

```
F1 分数对比 (10 samples, 1986 QA)

long_context   |==========================================| 0.472
auto_pgvector  |================================          | 0.357
auto_mysql     |===============================           | 0.347
agentic_pgvec  |==========================                | 0.294
agentic_mysql  |=========================                 | 0.286
               +------------------------------------------+
               0.0      0.1      0.2      0.3      0.4   0.5
```

#### 4.1.1 长上下文是金标准

长上下文取得最高 F1（0.472），在除对抗性外的所有类别中均最优。这确认了在上下文窗口允许时，提供完整对话文本仍然是最佳方案。但这种方法无法扩展到任意长度的对话历史。

#### 4.1.2 自动提取优于 Agentic

自动记忆提取（F1=0.357）显著优于 Agentic（0.294）。自动提取更系统化——处理所有对话内容，而非依赖 LLM Agent 的选择性工具调用，生成更高密度、语义更丰富的记忆。

#### 4.1.3 对抗鲁棒性与召回能力呈反相关

记忆方案达到较高对抗 F1（0.653-0.830），而长上下文仅 0.668。这是因为基于记忆的方法在未检索到相关记忆时自然返回"信息不可用"，这恰好是对抗性问题的正确答案。而长上下文有完整文本可用时，更容易产生看似合理但实际错误的回答。

### 4.2 类别分析

#### 4.2.1 时间推理普遍薄弱

时间类问题在所有场景中 F1 最低（0.043-0.091），包括长上下文（0.088）。这表明时间推理对 gpt-4o-mini 来说本质上很困难，与记忆架构无关。

根本原因：
- 对话使用相对时间引用（"去年"、"下个月"），需要根据 session 日期进行解析
- 即使记忆中有明确的 `[DATE:]` 前缀，模型仍难以计算时间关系

#### 4.2.2 多跳推理受益于 Agentic 记忆

Agentic（pgvector）在记忆方案中取得最高多跳 F1（0.178），超越 Auto（0.088）。这表明 Agentic 方法虽然总体提取的记忆较少，但创建了更具关联性的知识，有助于多跳推理。`datePrefixMemoryService` 注入的 `[DATE:]` 前缀对此有贡献。

#### 4.2.3 开放域问题依赖丰富上下文

长上下文在开放域问题中占据主导（F1=0.518），而记忆方案表现较弱（0.126-0.302）。开放域问题通常需要对对话上下文、偏好和态度的细致理解，这些很难用离散的记忆条目捕获。

### 4.3 后端对比：pgvector vs MySQL

| 场景 | pgvector F1 | MySQL F1 | 差值 |
| --- | ---: | ---: | ---: |
| Agentic | 0.294 | 0.286 | +0.008 |
| Auto | 0.357 | 0.347 | +0.010 |

pgvector 始终优于 MySQL：
- **语义匹配**：向量相似度能捕获关键字搜索遗漏的同义改述查询
- **Agentic 差距最小**：Agentic 记忆更短、关键字更密集，缩小了检索差距

### 4.4 方差分析

各样本 F1 分数显示明显方差：
- **长上下文**：0.429 - 0.539（范围 0.110），相对稳定
- **Auto pgvector**：0.204 - 0.441（范围 0.237），方差较大

记忆方案的高方差表明，某些对话结构本质上更难进行记忆提取和检索。话题交错更复杂的样本（如 locomo10_6, locomo10_8）得分往往更低。

---

## 5. 与外部基线对比

| 系统 | 模型 | F1 | 备注 |
| --- | --- | ---: | --- |
| GPT-4 (4K context) | GPT-4 | 0.321 | LoCoMo 论文基线 |
| GPT-3.5-16K | GPT-3.5 | 0.378 | LoCoMo 论文基线 |
| **trpc-agent-go (Long-Context)** | gpt-4o-mini | **0.472** | 本工作 |
| **trpc-agent-go (Auto pgvector)** | gpt-4o-mini | **0.357** | 本工作 |

> 注：由于模型版本和配置不同，直接对比仅供参考

长上下文结果（0.472）显著超越 LoCoMo 的 GPT-4 4K 基线（0.321），得益于 gpt-4o-mini 更大的上下文窗口。Auto pgvector 结果（0.357）与 GPT-3.5-16K 全上下文性能（0.378）接近。

---

## 6. 讨论

### 6.1 当前实现的优势

1. **日期感知记忆服务**：`datePrefixMemoryService` 自动为 Agentic 记忆注入 `[DATE: ...]` 前缀，无需依赖 LLM 遵从指令即可改善时间推理
2. **强对抗鲁棒性**：记忆方案达到 0.65-0.83 的对抗 F1，能正确识别不可回答问题
3. **自动提取方案**：后台提取器在记忆质量和系统复杂度之间提供了良好平衡

### 6.2 局限性与未来工作

1. **时间推理仍然薄弱**（所有场景 F1 < 0.1），后续应探索专用时间索引和推理模块
2. **多跳推理差距**：记忆方案难以跨 session 组合事实，图结构记忆可能有帮助
3. **开放域性能**：记忆压缩不可避免地丢失细节，分层记忆（摘要 + 细节）可能弥补此差距
4. **模型能力上限**：gpt-4o-mini 的提取和推理能力限制了所有场景，更强的模型（如 GPT-4o、Claude）可能显著改善结果

### 6.3 生产使用建议

| 使用场景 | 推荐方案 |
| --- | --- |
| 短对话历史 (< 50K tokens) | 长上下文（无需记忆） |
| 长期运行的 Agent（数月历史） | 自动提取 + pgvector |
| 低延迟要求 | Agentic + MySQL |

---

## 7. 结论

本评估证明 trpc-agent-go 的记忆系统在多种范式下均能提供有效的长期对话记忆。自动提取 + pgvector 方案取得了最佳的召回与鲁棒性平衡，达到长上下文基线 F1 的 75.6%，同时保持强对抗鲁棒性（0.771）。

核心结论：
1. **Auto > Agentic**：在 gpt-4o-mini 下的记忆方案有效性排序
2. **pgvector > MySQL**：语义检索质量始终更优
3. **时间推理** 是所有方案的主要瓶颈
4. **对抗鲁棒性** 是记忆系统的天然优势

---

## 附录

### A. 实验环境

| 组件 | 版本/配置 |
| --- | --- |
| 框架 | trpc-agent-go |
| 模型 | gpt-4o-mini |
| Embedding | text-embedding-3-small |
| PostgreSQL | 15+ with pgvector extension |
| MySQL | 8.0+ with full-text search |
| 数据集 | LoCoMo-10（10 样本，1,986 QA） |

### B. 完整类别数据（F1 / BLEU / LLM）

| 场景 | single-hop | multi-hop | temporal | open-domain | adversarial |
| --- | --- | --- | --- | --- | --- |
| Long-Context | 0.330/0.260/0.333 | 0.319/0.285/0.252 | 0.088/0.069/0.155 | 0.518/0.456/0.654 | 0.668/0.667/0.670 |
| Agentic pgvec | 0.146/0.106/0.122 | 0.178/0.160/0.107 | 0.091/0.075/0.137 | 0.126/0.114/0.141 | 0.830/0.830/0.830 |
| Agentic MySQL | 0.168/0.125/0.130 | 0.135/0.119/0.093 | 0.043/0.034/0.057 | 0.146/0.132/0.171 | 0.787/0.787/0.787 |
| Auto pgvec | 0.272/0.209/0.220 | 0.088/0.081/0.049 | 0.060/0.047/0.068 | 0.302/0.271/0.355 | 0.771/0.771/0.771 |
| Auto MySQL | 0.306/0.232/0.277 | 0.101/0.092/0.064 | 0.056/0.040/0.083 | 0.325/0.293/0.380 | 0.653/0.653/0.653 |

### C. 总评估时间

| 场景 | 后端 | 总时间 | 平均延迟/QA |
| --- | --- | --- | --- |
| Long-Context | - | 1h55m | 3,485ms |
| Agentic | pgvector | 2h45m | 4,998ms |
| Agentic | MySQL | 2h25m | 4,392ms |
| Auto | pgvector | 3h06m | 5,622ms |
| Auto | MySQL | 3h08m | 5,678ms |

---

## 参考文献

1. Maharana, A., Lee, D., Tulyakov, S., Bansal, M., Barbieri, F., and Fang, Y. "LoCoMo: Long-Context Conversational Memory." arXiv:2402.17753, 2024.
2. Hu, C., et al. "Memory in the Age of AI Agents." arXiv:2512.13564, 2024.
