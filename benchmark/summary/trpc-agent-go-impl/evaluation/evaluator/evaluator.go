//
// Tencent is pleased to support the open source community by making
// trpc-agent-go available.
//
// Copyright (C) 2025 Tencent.  All rights reserved.
//
// trpc-agent-go is licensed under the Apache License Version 2.0.
//

// Package evaluator provides evaluator extensions for summary benchmark.
// It reuses types from trpc-agent-go/evaluation/evaluator and adds
// benchmark-specific extensions like MultiRunEvaluator interface.
package evaluator

import (
	"context"

	"trpc.group/trpc-go/trpc-agent-go/evaluation/evalset"
	baseeval "trpc.group/trpc-go/trpc-agent-go/evaluation/evaluator"
	"trpc.group/trpc-go/trpc-agent-go/evaluation/metric"
	"trpc.group/trpc-go/trpc-agent-go/evaluation/status"
)

// Re-export base types from the main library for convenience.
type (
	// Evaluator is the base evaluator interface from the main library.
	Evaluator = baseeval.Evaluator
	// PerInvocationDetails contains additional evaluator-specific information.
	PerInvocationDetails = baseeval.PerInvocationDetails
	// ScoreResult represents the score and rationale for a single metric.
	ScoreResult = baseeval.ScoreResult
)

// MultiRunEvaluator extends Evaluator to support Pass@k style evaluation.
// It evaluates multiple runs against a baseline.
// NOTE: This is a benchmark-specific extension not present in the main library.
type MultiRunEvaluator interface {
	Evaluator
	// EvaluateMultiRun evaluates multiple runs against a baseline.
	// baselineRuns: results from baseline mode (e.g., full events).
	// testRuns: results from test mode (e.g., summary + delta events).
	EvaluateMultiRun(
		ctx context.Context,
		baselineRuns, testRuns [][]*evalset.Invocation,
		evalMetric *metric.EvalMetric,
	) (*EvaluateResult, error)
}

// EvaluateResult extends the base EvaluateResult with a Details map.
// This allows evaluators to return arbitrary benchmark-specific data.
// NOTE: This extends the main library's EvaluateResult with additional fields.
type EvaluateResult struct {
	// OverallScore is the overall score for this evaluation.
	OverallScore float64 `json:"overallScore,omitempty"`
	// OverallStatus represents pass/fail/not-evaluated for the evaluation run.
	OverallStatus status.EvalStatus `json:"overallStatus,omitempty"`
	// PerInvocationResults contains results for each invocation.
	PerInvocationResults []*PerInvocationResult `json:"perInvocationResults,omitempty"`
	// Details contains additional evaluator-specific information.
	// NOTE: This field is a benchmark-specific extension.
	Details map[string]any `json:"details,omitempty"`
}

// PerInvocationResult represents the evaluation result for a single invocation.
// NOTE: This extends the main library's PerInvocationResult with a map-based Details.
type PerInvocationResult struct {
	// ActualInvocation is the invocation generated by the agent.
	ActualInvocation *evalset.Invocation `json:"actualInvocation,omitempty"`
	// ExpectedInvocation is the expected invocation.
	ExpectedInvocation *evalset.Invocation `json:"expectedInvocation,omitempty"`
	// Score is the evaluator's score for this invocation.
	Score float64 `json:"score,omitempty"`
	// Status indicates the evaluation status of the invocation.
	Status status.EvalStatus `json:"status,omitempty"`
	// Details contains additional evaluator-specific information.
	// NOTE: This is map-based for flexibility, unlike the base library's struct.
	Details map[string]any `json:"details,omitempty"`
}
