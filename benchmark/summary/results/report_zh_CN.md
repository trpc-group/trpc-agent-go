# 会话摘要评测报告

**评测日期**：2026 年 1 月 23-26 日  
**模型**：deepseek-v3.2  
**数据集**：MT-Bench-101（子集）  
**测试用例总数**：627

## 摘要

本评测基于 MT-Bench-101 多轮对话数据集，评估 `trpc-agent-go` 会话摘要功能的有效性。评测从三个维度进行：

- **响应一致性**（权重 50%）：摘要后的上下文是否能产生语义等价的响应。
- **Token 效率**（权重 30%）：摘要带来的 token 节省。
- **信息保留率**（权重 20%）：对话历史中关键信息的保留程度。

### 核心发现

| 指标 | 数值 |
|------|------|
| 总体一致性得分 | 0.85 |
| Pass^1 通过率 | 93.9% |
| 平均 Token 节省 | -8.97% |
| 平均 Prompt 节省 | -1.29% |
| 平均信息保留率 | 83% |

**解读**：摘要系统保持了**较高的响应一致性**（85% 语义等价，94% 通过率），但 **Token 效率因任务类型而异**。信息保留率平均 83%，表明大部分关键细节得以保留。

## 分任务结果

| 任务 | 全称 | 用例数 | Token 节省 | Prompt 节省 | 一致性 | 保留率 | Pass^1 |
|------|------|-------:|-----------:|------------:|-------:|-------:|-------:|
| CC | 内容混淆 | 147 | -27.10% | -17.44% | 0.86 | 0.86 | 89.1% |
| CM | 上下文记忆 | 80 | +13.68% | +25.50% | 0.82 | 0.82 | 96.2% |
| GR | 通用推理 | 3 | +13.95% | +15.20% | 1.00 | 1.00 | 100.0% |
| IC | 指令澄清 | 150 | -0.63% | -0.44% | 0.85 | 0.82 | 95.3% |
| PI | 主动交互 | 87 | -28.32% | -1.43% | 0.81 | 0.70 | 96.6% |
| SC | 自我纠正 | 77 | -1.78% | -0.74% | 0.88 | 0.87 | 93.5% |
| TS | 话题转换 | 83 | -0.99% | -1.01% | 0.85 | 0.85 | 95.2% |
| **总计** | | **627** | **-8.97%** | **-1.29%** | **0.85** | **0.83** | **93.9%** |

## 任务类型分析

### 高效任务（正向 Token 节省）

1. **上下文记忆 (CM)**：Prompt 节省 +25.5%
   - 摘要有效压缩了长对话历史。
   - 高通过率（96.2%）表明响应质量可靠。

2. **通用推理 (GR)**：Prompt 节省 +15.2%
   - 样本量较小（3 个用例），但结果良好。
   - 一致性和保留率均达到满分。

### 挑战性任务（负向 Token 节省）

1. **内容混淆 (CC)**：Prompt 增加 17.44%
   - 需要消歧相似查询的任务依赖完整上下文。
   - 摘要可能丢失区分性细节，导致需要更多澄清。

2. **主动交互 (PI)**：Token 增加 28.32%，但 Prompt 仅增加 1.43%
   - 摘要上下文下模型生成了更多 completion tokens。
   - 较低的保留率（70%）表明部分对话细节丢失。

### 中性任务（接近零节省）

- **IC、SC、TS**：Token 节省在 ±2% 范围内，摘要影响不显著。

## 指标说明

### 响应一致性 (Pass^k)

使用 LLM 评估基线（完整上下文）和摘要响应之间的语义等价性。

- **得分**：0-1 的语义相似度。
- **Pass^1**：至少 1 次运行通过阈值（0.7）的用例百分比。

### Token 效率

```
Token 节省 % = (基线 Tokens - 摘要 Tokens) / 基线 Tokens × 100
Prompt 节省 % = (基线 Prompt Tokens - 摘要 Prompt Tokens) / 基线 Prompt Tokens × 100
```

负值表示摘要版本使用了**更多** token。

### 信息保留率

评估每轮对话的关键信息是否在摘要中保留。

- 从基线响应中提取关键事实。
- 验证这些事实是否出现在摘要上下文的响应中。
- 计算每轮和总体保留率。

## 建议

1. **任务感知摘要**：考虑对 CC（内容混淆）任务禁用摘要，因为消歧需要完整上下文。

2. **阈值调优**：当前事件阈值（2）对某些任务类型可能过于激进。建议根据对话特征自适应调整阈值。

3. **保留率优化**：PI（主动交互）任务的 70% 保留率表明摘要器可能丢弃了对话线索。建议对交互密集型对话保留更多上下文。

4. **扩展评测**：GR（通用推理）结果优秀但仅有 3 个用例，建议进行更全面的测试。

## 方法论

### 评测流程

1. **基线运行**：使用完整上下文执行对话（无摘要）。
2. **摘要运行**：使用启用摘要的相同对话（事件阈值 = 2）。
3. **结果对比**：测量 token 使用、响应相似度和信息保留。

### 配置

```
模型: deepseek-v3.2
事件阈值: 2
一致性阈值: 0.70
保留率阈值: 0.70
K 值: 1, 2, 4
权重: 一致性 50%, Token 30%, 保留率 20%
```

## 参考文献

- [MT-Bench-101 论文 (ACL 2024)](https://arxiv.org/abs/2402.14762)
- [τ-bench 论文](https://arxiv.org/abs/2406.12045)
- [τ²-bench 论文](https://arxiv.org/abs/2506.07982)
